{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting docopt==0.6.2 (from pipreqs)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ipython==8.12.3 (from pipreqs)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting nbconvert<8.0.0,>=7.11.0 (from pipreqs)\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting yarg==0.1.9 (from pipreqs)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: backcall in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (0.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (0.7.5)\n",
      "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 (from ipython==8.12.3->pipreqs)\n",
      "  Downloading prompt_toolkit-3.0.45-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (2.14.0)\n",
      "Collecting stack-data (from ipython==8.12.3->pipreqs)\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: traitlets>=5 in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (3.10.0.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/karvala/anaconda3/lib/python3.9/site-packages (from ipython==8.12.3->pipreqs) (4.8.0)\n",
      "Requirement already satisfied: requests in /home/karvala/anaconda3/lib/python3.9/site-packages (from yarg==0.1.9->pipreqs) (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.8.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.0.0)\n",
      "Requirement already satisfied: defusedxml in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.8.1)\n",
      "Collecting jinja2>=3.0 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.8.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.1.2)\n",
      "Collecting markupsafe>=2.0 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.3)\n",
      "Collecting nbformat>=5.7 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (21.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.4.3)\n",
      "Collecting tinycss2 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.12.0)\n",
      "Requirement already satisfied: webencodings in /home/karvala/anaconda3/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/karvala/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=3.6->nbconvert<8.0.0,>=7.11.0->pipreqs) (3.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython==8.12.3->pipreqs) (0.8.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.1.12)\n",
      "Requirement already satisfied: async-generator in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.1)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/karvala/anaconda3/lib/python3.9/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (3.2.0)\n",
      "Collecting jupyter-core>=4.7 (from nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting platformdirs>=2.5 (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs)\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting traitlets>=5 (from ipython==8.12.3->pipreqs)\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/karvala/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython==8.12.3->pipreqs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/karvala/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->pipreqs) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/karvala/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/karvala/anaconda3/lib/python3.9/site-packages (from packaging->nbconvert<8.0.0,>=7.11.0->pipreqs) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/karvala/anaconda3/lib/python3.9/site-packages (from requests->yarg==0.1.9->pipreqs) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/karvala/anaconda3/lib/python3.9/site-packages (from requests->yarg==0.1.9->pipreqs) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from requests->yarg==0.1.9->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/karvala/anaconda3/lib/python3.9/site-packages (from requests->yarg==0.1.9->pipreqs) (3.2)\n",
      "Collecting executing>=1.2.0 (from stack-data->ipython==8.12.3->pipreqs)\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack-data->ipython==8.12.3->pipreqs)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pure-eval (from stack-data->ipython==8.12.3->pipreqs)\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/karvala/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (58.0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.8.2)\n",
      "Requirement already satisfied: tornado>=4.1 in /home/karvala/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.1)\n",
      "Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.4/257.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Downloading prompt_toolkit-3.0.45-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=33c7984d6a91fe10ac3a2a360c210cb08b0932161ed4ebcb4df15af47e1dd20c\n",
      "  Stored in directory: /home/karvala/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built docopt\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pure-eval, fastjsonschema, docopt, traitlets, tinycss2, prompt-toolkit, platformdirs, mistune, markupsafe, executing, asttokens, yarg, stack-data, jupyter-core, jinja2, nbformat, ipython, nbconvert, pipreqs\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.0\n",
      "    Uninstalling traitlets-5.1.0:\n",
      "      Successfully uninstalled traitlets-5.1.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.20\n",
      "    Uninstalling prompt-toolkit-3.0.20:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.20\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.8.1\n",
      "    Uninstalling jupyter-core-4.8.1:\n",
      "      Successfully uninstalled jupyter-core-4.8.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.1.3\n",
      "    Uninstalling nbformat-5.1.3:\n",
      "      Successfully uninstalled nbformat-5.1.3\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.29.0\n",
      "    Uninstalling ipython-7.29.0:\n",
      "      Successfully uninstalled ipython-7.29.0\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.1.0\n",
      "    Uninstalling nbconvert-6.1.0:\n",
      "      Successfully uninstalled nbconvert-6.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.1.4 which is incompatible.\n",
      "cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.1.5 which is incompatible.\n",
      "ipykernel 6.4.1 requires ipython<8.0,>=7.23.1, but you have ipython 8.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asttokens-2.4.1 docopt-0.6.2 executing-2.0.1 fastjsonschema-2.19.1 ipython-8.12.3 jinja2-3.1.4 jupyter-core-5.7.2 markupsafe-2.1.5 mistune-3.0.2 nbconvert-7.16.4 nbformat-5.10.4 pipreqs-0.5.0 platformdirs-4.2.2 prompt-toolkit-3.0.45 pure-eval-0.2.2 stack-data-0.6.3 tinycss2-1.3.0 traitlets-5.14.3 yarg-0.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Crear requirements\n",
    "#%pip install pipreqs\n",
    "#%pipreqs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intalar pymupdf\n",
    "# %pip install pymupdf\n",
    "\n",
    "#importar fitz para usar pymupdf (fitz es pymupdf)\n",
    "import fitz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar e importar la biblioteca pendulum y datetime para trabajar con fechas\n",
    "# %pip install pendulum\n",
    "from datetime import datetime\n",
    "import pendulum\n",
    "\n",
    "# Definir timezone e idioma en la biblioteca pendulum\n",
    "tz = pendulum.timezone('Europe/Paris')\n",
    "pendulum.set_locale('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intalar e importar la biblioteca para trabajar con codigos postales\n",
    "# %pip install pgeocode\n",
    "\n",
    "import pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formato_fecha(fecha):\n",
    "    \"\"\" Convierte fechas en formato DD/MM/YYYY o \"DD de MMMM YYYY al formato DD.MM.YYYY.\n",
    "    Args:\n",
    "        fecha (Date or String): fecha a cambiar de formato.\n",
    "    Returns:\n",
    "        dt_final (Date): devuelve la fecha con el formato cambiado.\n",
    "    \"\"\"  \n",
    "    dt = ''\n",
    "    try:\n",
    "        datetime.strptime(fecha, \"%d.%m.%Y\")\n",
    "        return fecha\n",
    "    except ValueError:\n",
    "       pass\n",
    "        \n",
    "    if '/' in fecha:\n",
    "        dt = pendulum.from_format(fecha, 'DD/MM/YYYY')\n",
    "    elif 'de' in fecha:\n",
    "        dt = pendulum.from_format(fecha.replace(' de', ''), 'DD MMMM YYYY')\n",
    "    else:\n",
    "        dt_final = fecha\n",
    "    try:\n",
    "        dt_final = dt.format('DD.MM.YYYY')\n",
    "    except Exception:\n",
    "        dt_final = fecha\n",
    "\n",
    "    return dt_final    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_CP(direccion):\n",
    "    \"\"\" Divide una string en una lista por un código de 5 dígitos (incluido en la lista devuelta).\n",
    "    Args:\n",
    "        direccion (String): línea de texto que incluya un código postal.\n",
    "    Returns:\n",
    "        lista (list): devuelve una lista separando por CP. \n",
    "    \"\"\"\n",
    "    return re.split(r\"(\\d{5})\", direccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extaer_pag_pdf(ruta, num):\n",
    "    \"\"\" Extrae el texto de un pdf convirtiéndolo en una lista dónde cada línea del texto es un elenmento de la lista.\n",
    "    Args:\n",
    "        ruta (String): ruta al archivo pdf que se va a leer.\n",
    "        num (int): número de la página del pdf que se quiere leer (empezando en 0).\n",
    "    Returns:\n",
    "        lista (list): devuelve una lista separando cada línea del texto como un elemento de la lista.\n",
    "    \"\"\"\n",
    "    file = fitz.open(ruta)\n",
    "    pymupdf_text = []\n",
    "\n",
    "    for page in file:\n",
    "        pymupdf_text.append(page.get_text())\n",
    "\n",
    "    return pymupdf_text[num].split('\\n')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el diccionario que se convertirá en el archivo JSON final con los datos a conseguir\n",
    "diccionario_final = {\n",
    "    \"nombre_cliente\": \"\",\n",
    "    \"dni_cliente\": \"\",\n",
    "    \"calle_cliente\": \"\",\n",
    "    \"cp_cliente\": \"\",\n",
    "    \"población_cliente\": \"\",\n",
    "    \"provincia_cliente\": \"\",\n",
    "    \"nombre_comercializadora\": \"\",\n",
    "    \"cif_comercializadora\": \"\",\n",
    "    \"dirección_comercializadora\": \"\",\n",
    "    \"cp_comercializadora\": \"\",\n",
    "    \"población_comercializadora\": \"\",\n",
    "    \"provincia_comercializadora\": \"\",\n",
    "    \"número_factura\": \"\",\n",
    "    \"inicio_periodo\": \"\",\n",
    "    \"fin_periodo\": \"\",\n",
    "    \"importe_factura\": \"\",\n",
    "    \"fecha_cargo\": \"\",\n",
    "    \"consumo_periodo\": \"\",\n",
    "    \"potencia_contratada\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_a_dicc_y_lista(lineas_pdf):\n",
    "    \"\"\" De una lista de strings, se eliminan las líneas vacias y se crea un diccionario con los elementos de los que se pueden extraer pares key/valor mediante la separación por ':' y, por otro lado, se crea una lista con todos los datos para tenerlos ordenados.\n",
    "    Args:\n",
    "        lineas_pdf (list): lista de strigns.\n",
    "    Returns:\n",
    "        dict_lineas(dict): devuelve un diccionario con los pares key/valor de las líneas que incuian ':' y el resto de líneas con una key numerada.\n",
    "        lista_lineas (list): devuelve una lista donde cada elemnto es una string (misma lista de args sin elementos vacíos).\n",
    "    \"\"\"\n",
    "    dict_lineas = {}\n",
    "    lista_lineas = []\n",
    "    contador = 0\n",
    "    for linea in lineas_pdf:\n",
    "        linea = linea.strip()\n",
    "        #Se eliminan lineas vacias (o de solo un espacio)\n",
    "        if linea != '':\n",
    "            lista_lineas.append(linea)\n",
    "            #Se dividen las líneas por el primer ':' para separarlas en Key/valor en el diccionario\n",
    "            if ':' in linea:\n",
    "                lista_linea = linea.split(':', 1)\n",
    "                dict_lineas[lista_linea[0]] = lista_linea[1].strip() \n",
    "            else:\n",
    "                # En caso de no contar con ':' en la línea, se añade al diccionario con la key:'otro' más un número incremental\n",
    "                contador += 1\n",
    "                dict_lineas[f'otro{contador}'] = linea\n",
    "    return dict_lineas, lista_lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info(dict_lineas, lista_lineas):\n",
    "    # Se obtienen todos los datos que se pueden extraer mediante las llaves del diccionario \n",
    "    for key in dict_lineas.keys():\n",
    "        try:\n",
    "            if 'nº' in key.lower() and 'factura' in key.lower():\n",
    "                diccionario_final[\"número_factura\"] = dict_lineas[key]\n",
    "            if 'periodo' in key.lower() or 'período' in key.lower():\n",
    "                lista_fechas = dict_lineas[key].replace('del', '').replace('de', '').split('(')[0]\n",
    "                if 'al' in dict_lineas[key].lower():\n",
    "                    fechas_consumo = lista_fechas.split(' al ')\n",
    "                elif 'a' in dict_lineas[key].lower():    \n",
    "                    fechas_consumo = lista_fechas.split(' a ')\n",
    "                diccionario_final[\"inicio_periodo\"] = formato_fecha(fechas_consumo[0].strip())\n",
    "                diccionario_final[\"fin_periodo\"] = formato_fecha(fechas_consumo[-1].strip())\n",
    "            \n",
    "            if 'potencia' in key.lower() and 'importe' not in key.lower():\n",
    "                diccionario_final[\"potencia_contratada\"] = dict_lineas[key].split()[0]      \n",
    "            if 'titular' in key.lower() or 'nombre' in key.lower() :\n",
    "                diccionario_final[\"nombre_cliente\"] = dict_lineas[key]     \n",
    "            if 'dirección' in key.lower():\n",
    "                print(f\"direccion: {key}\")\n",
    "                try:\n",
    "                    lista_direccion = separa_CP(dict_lineas[key])\n",
    "                    diccionario_final[\"calle_cliente\"] = lista_direccion[0]\n",
    "                    diccionario_final[\"cp_cliente\"] = lista_direccion[1]\n",
    "                    diccionario_final[\"población_cliente\"] = lista_direccion[2]\n",
    "                    if diccionario_final[\"calle_cliente\"] != '' and diccionario_final[\"cp_cliente\"] != '' and diccionario_final[\"población_cliente\"] != '':\n",
    "                        break\n",
    "                    else:\n",
    "                        continue \n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Se duplica el for en el caso del cif y el Nif para poder romper el loop después de la primera localización y asegurarnos que es el de la comercializadora y el cliente respectivamente\n",
    "    for key in dict_lineas.keys():\n",
    "        if 'fecha' in key.lower() and 'cargo' in key.lower():\n",
    "            diccionario_final[\"fecha_cargo\"] = formato_fecha(dict_lineas[key])\n",
    "            break\n",
    "    for key in dict_lineas.keys():\n",
    "        if 'diccionario_final[\"fecha_cargo\"]' == '' and 'fecha' in key.lower() and 'emisión' in key.lower():\n",
    "                diccionario_final[\"fecha_cargo\"] = formato_fecha(dict_lineas[key])\n",
    "                break\n",
    "            \n",
    "    for key in dict_lineas.keys():\n",
    "        try:\n",
    "            if 'importe' in key.lower() and 'factura' in key.lower():\n",
    "                print(dict_lineas[key])\n",
    "                diccionario_final[\"importe_factura\"] = dict_lineas[key].split()[0]\n",
    "                break\n",
    "        except Exception:\n",
    "            continue    \n",
    "\n",
    "    for key in dict_lineas.keys():\n",
    "        if 'nif' in key.lower():\n",
    "            diccionario_final[\"dni_cliente\"] = dict_lineas[key]  \n",
    "            break\n",
    "\n",
    "    # Mediante un enumerate extraemos todos los datos que sabemos que estan cerca unos de otros en la lista.\n",
    "    lista_consumo = []\n",
    "    lista_direccion = []\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "\n",
    "        if 'potencia' in linea.lower() and diccionario_final[\"potencia_contratada\"] == '':\n",
    "            if 'kw' in lista_lineas[indice+1].lower():\n",
    "                diccionario_final[\"potencia_contratada\"] = lista_lineas[indice+1].split()[0]  \n",
    "\n",
    "        if diccionario_final[\"dni_cliente\"] == '' or diccionario_final[\"dni_cliente\"] == None or len(diccionario_final[\"dni_cliente\"]) != 9:\n",
    "            try:\n",
    "                dni = re.search(r\"[0-9]{8}[A-Za-z]\", linea)\n",
    "                diccionario_final[\"dni_cliente\"] = dni.group()\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if (diccionario_final[\"inicio_periodo\"] == '' or diccionario_final[\"fin_periodo\"] == '') and ('periodo' in linea.lower() or 'período' in linea.lower()):\n",
    "            fechas = linea.replace('periodo', '').replace('período', '').replace('Periodo', '').replace('Período', '').replace('del', '').replace('de', '').strip()\n",
    "            \n",
    "            if 'a' in linea.lower():    \n",
    "                fechas_consumo = fechas.split(' a ')\n",
    "            elif 'al' in linea.lower():\n",
    "                fechas_consumo = fechas.split(' al ')\n",
    "            print(f\"fechas consumo2: {fechas_consumo}\")\n",
    "    \n",
    "            diccionario_final[\"inicio_periodo\"] = formato_fecha(fechas_consumo[0].strip())\n",
    "            diccionario_final[\"fin_periodo\"] = formato_fecha(fechas_consumo[-1].strip())\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        if 'dirección' in linea.lower() and 'suministro' in linea.lower() and diccionario_final[\"calle_cliente\"] == '':\n",
    "            try:\n",
    "                lista_direccion.append(linea) \n",
    "                lista_direccion.append(lista_lineas[indice+1]) \n",
    "                direccion_suministro = ' '.join(lista_direccion)\n",
    "                direccion_dividir = direccion_suministro.split(':', 1)\n",
    "                direccion = direccion_dividir[1].strip().split(',')\n",
    "                diccionario_final[\"calle_cliente\"] = direccion[0].strip() \n",
    "                diccionario_final[\"población_cliente\"] = direccion[1].strip()  \n",
    "            except Exception:\n",
    "                direccion_entera = linea.split(':', 1)[1]\n",
    "                direccion = separa_CP(direccion_entera)\n",
    "                diccionario_final[\"calle_cliente\"] = direccion[0].strip() \n",
    "                diccionario_final[\"población_cliente\"] = direccion[2].strip()  \n",
    "        \n",
    "        \n",
    "    # Se duplican los bucles for para poder pararlos después de la primera aparición en aquella información repetida a lo largo del pdf y que puede dar problemas.\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if ('importe' in linea.lower() and 'factura' in linea.lower()) or ('total' in linea.lower() and 'pagar' in linea.lower()) and (diccionario_final[\"importe_factura\"] == '' or diccionario_final[\"importe_factura\"] <= 0.0):\n",
    "            try:\n",
    "                importe = float(lista_lineas[indice-1].split()[0].replace(',','.'))\n",
    "                diccionario_final[\"importe_factura\"] = str(importe)\n",
    "                \n",
    "            except Exception:\n",
    "                lista_importe = lista_lineas[indice].replace(',','.').split()\n",
    "                print(f\"lista_importe: {lista_importe}\")\n",
    "                for elemento in lista_importe:\n",
    "                    try:\n",
    "                        importe = float(elemento)\n",
    "                        diccionario_final[\"importe_factura\"] = str(importe).replace('.', ',')\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                \n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if 'cif' in linea.lower():\n",
    "            diccionario_final[\"cif_comercializadora\"] = linea.split()[-1].replace('.', '').strip()\n",
    "            try:\n",
    "                if len(diccionario_final[\"cif_comercializadora\"]) != 9:\n",
    "                    diccionario_final[\"cif_comercializadora\"] = ''\n",
    "                    diccionario_final[\"cif_comercializadora\"] = lista_lineas[indice+1].replace('.', '').strip()\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if 'cif' in linea.lower():\n",
    "            try:                \n",
    "                diccionario_final[\"nombre_comercializadora\"] = lista_lineas[indice-1]\n",
    "                nombre = re.search(r\"^[\\sáéíóúÁÉÍÓÚàÀÈÈÒòa-z,A-Z]+S\\.[AL]\\.\", diccionario_final[\"nombre_comercializadora\"])\n",
    "                diccionario_final[\"nombre_comercializadora\"] = nombre.group()\n",
    "                for x in range(-2, 3):\n",
    "                    direccion_comercializadora = separa_CP(lista_lineas[indice+x])\n",
    "                    diccionario_final[\"cp_comercializadora\"] = direccion_comercializadora[1].strip()\n",
    "                    if len(direccion_comercializadora[1]) == 5: \n",
    "                        diccionario_final[\"dirección_comercializadora\"] = direccion_comercializadora[0].strip()\n",
    "                        break\n",
    "                    else:\n",
    "                        continue      \n",
    "            except Exception:\n",
    "                continue\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if (diccionario_final[\"dirección_comercializadora\"] == '' or len(diccionario_final[\"dirección_comercializadora\"]) < 5) and 'social' in linea.lower():\n",
    "            try:\n",
    "                lista_comercializadora = linea.split(':', 1)\n",
    "                nombre = re.search(r\"^[\\sa-z,A-Z]+S\\.[AL]\\.\", lista_comercializadora[0])\n",
    "                diccionario_final[\"nombre_comercializadora\"] = nombre.group()\n",
    "\n",
    "                lista_direccion_comercial = separa_CP(lista_comercializadora[-1])\n",
    "                diccionario_final[\"dirección_comercializadora\"] = lista_direccion_comercial[0].strip()\n",
    "                diccionario_final[\"cp_comercializadora\"] = lista_direccion_comercial[1]\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if 'cif' in linea.lower():        \n",
    "            try:\n",
    "                if diccionario_final[\"nombre_cliente\"] == '':\n",
    "                    diccionario_final[\"nombre_cliente\"] = lista_lineas[indice+2]\n",
    "                    if diccionario_final[\"calle_cliente\"] == '':\n",
    "                        diccionario_final[\"calle_cliente\"] = lista_lineas[indice+3]\n",
    "                    direccion_cliente = separa_CP(lista_lineas[indice+4])\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue        \n",
    "                     \n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if 'consumo' in linea.lower() and 'p1' in linea.lower() and diccionario_final[\"consumo_periodo\"] == '':\n",
    "            try: \n",
    "                consumo = float(lista_lineas[indice+1].split('kWh')[0].strip())\n",
    "                diccionario_final[\"consumo_periodo\"] = consumo\n",
    "                break \n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if 'consumo' in linea and (diccionario_final['consumo_periodo'] == '' or 'xx' in str(diccionario_final['consumo_periodo']).lower()):\n",
    "            for x in range(1,5):\n",
    "                if 'kwh' in lista_lineas[indice+x].lower():\n",
    "                    try:\n",
    "                        diccionario_final['consumo_periodo'] = int(linea.split()[0])\n",
    "                        if diccionario_final['consumo_periodo'] != '' or 'xx' not in str(diccionario_final['consumo_periodo']).lower():\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "    for indice, linea in enumerate(lista_lineas):\n",
    "        if diccionario_final['cp_cliente'] == '':\n",
    "            if diccionario_final['nombre_cliente'].lower() in linea.lower():\n",
    "                cp = re.search(r\"[\\d]{5}\", lista_lineas[indice+2])\n",
    "                diccionario_final[\"cp_cliente\"] = cp.group()\n",
    "                diccionario_final[\"calle_cliente\"] = lista_lineas[indice+1]\n",
    "                break\n",
    "\n",
    "                           \n",
    "    nomi = pgeocode.Nominatim('es')\n",
    "    diccionario_final[\"provincia_cliente\"] = nomi.query_postal_code(diccionario_final[\"cp_cliente\"])['county_name']              \n",
    "    diccionario_final[\"población_cliente\"] = nomi.query_postal_code(diccionario_final[\"cp_cliente\"])['place_name']              \n",
    "    diccionario_final[\"provincia_comercializadora\"] = nomi.query_postal_code(diccionario_final[\"cp_comercializadora\"])['county_name']       \n",
    "    diccionario_final[\"población_comercializadora\"] = nomi.query_postal_code(diccionario_final[\"cp_comercializadora\"])['place_name']       \n",
    "\n",
    "    for linea in lista_lineas:\n",
    "        lista_pueblos = diccionario_final[\"población_cliente\"].split(',')\n",
    "        for pueblo in lista_pueblos:\n",
    "            pueblo = pueblo.strip()\n",
    "            if pueblo.lower() in linea.lower():\n",
    "                diccionario_final[\"población_cliente\"] = pueblo\n",
    "                break\n",
    "    for linea in lista_lineas:\n",
    "        lista_pueblos = str(diccionario_final[\"población_comercializadora\"]).split(',')\n",
    "        for pueblo in lista_pueblos:\n",
    "            pueblo = pueblo.strip()\n",
    "            if pueblo.lower() in linea.lower():\n",
    "                diccionario_final[\"población_comercializadora\"] = pueblo\n",
    "                break\n",
    "\n",
    "    return diccionario_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lectura_y_extraccion(ruta, min, max, pag=0):\n",
    "    for num_pdf in range (min, max+1):\n",
    "        lineas_pdf = extaer_pag_pdf(f\"pdfs/factura_{num_pdf}.pdf\", pag)\n",
    "        dict_lineas, lista_lineas = pdf_a_dicc_y_lista(lineas_pdf)\n",
    "        diccionario_final = extraer_info(dict_lineas, lista_lineas)\n",
    "        return diccionario_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nombre_cliente': '',\n",
       " 'dni_cliente': '',\n",
       " 'calle_cliente': '',\n",
       " 'cp_cliente': '',\n",
       " 'población_cliente': '',\n",
       " 'provincia_cliente': '',\n",
       " 'nombre_comercializadora': '',\n",
       " 'cif_comercializadora': '',\n",
       " 'dirección_comercializadora': '',\n",
       " 'cp_comercializadora': '',\n",
       " 'población_comercializadora': '',\n",
       " 'provincia_comercializadora': '',\n",
       " 'número_factura': '',\n",
       " 'inicio_periodo': '',\n",
       " 'fin_periodo': '',\n",
       " 'importe_factura': '',\n",
       " 'fecha_cargo': '',\n",
       " 'consumo_periodo': '',\n",
       " 'potencia_contratada': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lista_lineas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlista_lineas\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lista_lineas' is not defined"
     ]
    }
   ],
   "source": [
    "lista_lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Las cuentas claras..................................................................................', 'A continuación le presentamos información detallada sobre su/s contrato/s y factura.', 'Electricidad', 'Nº contrato de acceso', '(ELECTRO DISTRIBUCION DE ALMODOVAR DEL CAMPO SA):', '924599018933', 'Fecha final de contrato: 14.03.2018', 'Datos instalación electricidad', 'Potencia contratada:', '2,668 kW', 'Tarifa de acceso: 2.0A', 'Cuantía Peaje:1 XX,XX €', 'Código CUPS: ES7425796885725250OBEN', 'Información lecturas / consumos', 'Lectura actual:', 'Lectura anterior:', 'Consumo:', 'Llano real', 'Llano real', 'Llano', '14.03.2018', '13.01.2018', '23360 kWh', '23114 kWh', '246 kWh', 'Los costes de energía que se le aplican se determinan en el BOE de', 'fecha 26.12.20XX. Servicio: 97,337%, Permanentes: 0,150%,', 'Diversificación y Seguridad de abastecimiento: 2,513%.', 'Se aplica el precio del alquiler según BOE N 185 de 03.08.20XX.', 'Composición del término de energía: precio fijo (0,0XXXXX euros/kWh y', '0,0XXXXX euros/kWh), peaje acceso¹ (0,0XXXXX euros/kWh) y otros', 'costes regulados¹ (0,0XXXX euros/kWh y 0,0XXXXX euros/kWh).', 'Electricidad', 'Consumo periodo 1 real', 'Consumo periodo 2 real', 'Consumo periodo 1 estimado', 'Consumo periodo 2 estimado', '1800', '1600', '1400', '1200', '1000', '800', '600', '400', '200', '0', '1 Importe que la compañía comercializadora debe pagar a la compañía distribuidora correspondiente a la facturación de acceso a su red, de acuerdo', 'con el tipo de peaje aplicable de conformidad con el Real Decreto 1164/20XX de 26 de octubre para energía eléctrica y Real Decreto 949/2001 de 3', 'de', 'agosto para gas natural.', 'Si desea información detallada sobre su/s contrato/s e histórico de consumo, entre en su Área Privada en www.enerver.es/areaprivada.', 'Información de interés............................................................................', 'Ene.X', 'Feb.X', 'Mar.X', 'Abr.X', 'May.X', 'Jun.X', 'Jul.X', 'Ago.X', 'Sep.X', 'Oct.X', 'Nov.X', 'Dic.X', 'Ene.X', 'Feb.X', 'Mar.X', 'Abr.X', 'May.X', 'Jun.X', 'Jul.X', 'Ago.X', 'Sep.X', 'Oct.X', 'Nov.X', 'Dic.X']\n"
     ]
    }
   ],
   "source": [
    "for key in diccionario_final.keys():\n",
    "    if diccionario_final[key] == '':\n",
    "        lineas_pdf2 = extaer_pag_pdf(\"pdfs/factura_5.pdf\", 1)\n",
    "        dict_lineas2, lista_lineas2 = pdf_a_dicc_y_lista(lineas_pdf2)\n",
    "        diccionario_final2 = extraer_info(dict_lineas2, lista_lineas2)\n",
    "        print(lista_lineas2)\n",
    "        diccionario_final[key] = diccionario_final2[key]\n",
    "    else:\n",
    "        continue    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nombre_cliente': 'SATURNINO MALTÉS NARANJO',\n",
       " 'dni_cliente': '13714122G',\n",
       " 'calle_cliente': 'Calle de la Fuente de Antón Merlo ',\n",
       " 'cp_cliente': '24920',\n",
       " 'población_cliente': 'Aldea Del Puente, Sahelices Del Payuelo',\n",
       " 'provincia_cliente': 'León',\n",
       " 'nombre_comercializadora': 'ENERVER ENERGIA, S.L.',\n",
       " 'cif_comercializadora': 'B24726044',\n",
       " 'dirección_comercializadora': 'CALLE 42, POLIGONO EL BONY,',\n",
       " 'cp_comercializadora': '46740',\n",
       " 'población_comercializadora': 'Carcaixent',\n",
       " 'provincia_comercializadora': 'Valencia',\n",
       " 'número_factura': 'KS8622022848',\n",
       " 'inicio_periodo': '13.01.2018',\n",
       " 'fin_periodo': '14.03.2018',\n",
       " 'importe_factura': '0.0',\n",
       " 'fecha_cargo': '19.03.2018',\n",
       " 'consumo_periodo': '',\n",
       " 'potencia_contratada': '2,668'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nombre_cliente': 'SATURNINO MALTÉS NARANJO',\n",
       " 'dni_cliente': '13714122G',\n",
       " 'calle_cliente': 'Calle de la Fuente de Antón Merlo ',\n",
       " 'cp_cliente': '24920',\n",
       " 'población_cliente': 'Aldea Del Puente, Sahelices Del Payuelo',\n",
       " 'provincia_cliente': 'León',\n",
       " 'nombre_comercializadora': 'ENERVER ENERGIA, S.L.',\n",
       " 'cif_comercializadora': 'B24726044',\n",
       " 'dirección_comercializadora': 'CALLE 42, POLIGONO EL BONY,',\n",
       " 'cp_comercializadora': '46740',\n",
       " 'población_comercializadora': 'Carcaixent',\n",
       " 'provincia_comercializadora': 'Valencia',\n",
       " 'número_factura': 'KS8622022848',\n",
       " 'inicio_periodo': '13.01.2018',\n",
       " 'fin_periodo': '14.03.2018',\n",
       " 'importe_factura': '0.0',\n",
       " 'fecha_cargo': '19.03.2018',\n",
       " 'consumo_periodo': '',\n",
       " 'potencia_contratada': '2,668'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import json\\nwith open(\"json_meu/factura_5_meu.json\", \"w\") as fp:\\n    json.dump(diccionario_final, fp, ensure_ascii=False) '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import json\n",
    "with open(\"json_meu/factura_5_meu.json\", \"w\") as fp:\n",
    "    json.dump(diccionario_final, fp, ensure_ascii=False) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
